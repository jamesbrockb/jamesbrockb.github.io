---
layout: post
title:      "Picking a Classification Data Set and Model"
date:       2020-10-08 15:35:18 -0400
permalink:  picking_a_classification_data_set_and_model
---


We’re back with another blog post. Today I will be discussing some of the challenges I’ve found myself in when working through a classification model. For those who do not know what a classification model is, it may sound like a simple task or maybe you think it’s just one type of model. You’d be in the same boat as myself when I started to look at the high level interpretation of the project. Needless to say, it’s much, much more. However, there is a silver lining. While there are multiple ways to visualize and or execute your classification model, you don’t have to use every single way. Once you’ve identified your data set and the problem you’re looking to identify, you should hopefully be able to make an educated choice when it comes to the model you’re planning on using. Throughout this post I’ll be talking about, picking a data set and figuring out which model you’re going to use. To also add a note for the reader, while I’m writing this all down, it’s also going to be helping me decide which model I’m going to use. So we’re both learning from this!

So let’s talk about the data set. Number one, please pick something you’re interested in. I can’t imagine someone saying that running classification models is the most fun they’ve ever had. Try and pick something you’re going to have fun with. I can’t stress that enough. We were given a few different options of preset data to choose from as well as the ability to research and find our own datasets. Luckily for me, there was a pre chosen data set that interested me. Again, if you want to go out and explore some other datasets, go ahead and do so. I for instance chose a data set that was about churn rates of existing customers. I’m in sales at the moment and I’m hoping to take this certification and apply it directly to business needs, soo this one was kind of a no brainer for me. Now comes the interesting part, which classification model are we going to choose. Well there’s certainly an abundance. The ones I’m going to be focusing on exploring with you (and myself) are Logistic Regression, Decision Trees / Random Forests and Support Vector Machines. Using one of these models will help solve the question of, what’s the likelihood of a customer churning and what features in the data set are the most important / influential on a customer churning or not.

Logistic regression models are known for estimating ‘discrete values’, (binary, boolean etc.) based on a set of independent variables. From what we explored in my last blog post this may sound somewhat familiar. With logistic regression we’re predicting the probabilities of each event by fitting our data to the ‘logit function’. Again, since we’re predicting probability and ealing with discrete values our results will be between 0 and 1. Now with all of the models we’re going to explore you can always improve the model by playing around with certain parameters or changing (removing) some of the features. Given the information I’ve uncovered / learned about logistic regression, I personally don’t want to go this route for my project. I want to use something a bit more powerful.

Next we’re going to talk about decision trees. This is one of my instructors favorite ways to model their data and it’s a popular one amongst a lot of others. One of the nice things about decision trees is that it can solve both regression and classification problems. I want to paint a picture that will hopefully give you some high level clarity into how the algorithm works. Let’s use my data set. Churn will be our decision tree, or tree trunk if you will. Then each feature will be its own branch with even smaller branches going off of the feature, with different orders of features. Did I lose you there? Think of it this way, did the customer churn because of the voicemail plan? No? Well what else could it be, let’s go to the next feature. So on and so forth. But there is a branch for every feature all with their own order. Once the algorithm completes, it will spit back to you which decision node (branch) was the most accurate at predicting the churn. This will most likely be the model I use since I can already visualize it in my head.

Finally we have support vectors which is a really interesting model as well. Picture you have a scatter plot with two sets of data. For example purposes, let’s say the two sets of data are separated equally. So equally in fact that you could draw a line perfectly between them. The points of the two data sets that fall closest to this line are known as the support vectors. Obviously this isn’t a perfect world and we’re going to have a lot more than two pieces of data. Which honestly begs the point of me walking you and myself through this, is that we want a clean and simple data set. Otherwise the amount of time to train the data set would take a lot of time while there are other classification models which perform more efficiently.

Fitting Model:
<img src="https://raw.githubusercontent.com/jamesbrockb/images/master/randomforest.png">

Model Evaluation:
<img src="https://raw.githubusercontent.com/jamesbrockb/images/master/rf%20model.png">

In conclusion, for myself personally, I chose to pursue the random forests and a dash of XGBoost (which we didn’t get into). No need to worry as XGB is relatively simple and isn’t hard to interpret with some personal research. After completing my model, I was able to have a recall of 1.00 and an overall accuracy of ~97%. Which in my personal opinion, am very proud of. Overall this project was not as demanding as I had anticipated it to be. The models really do a lot of the work for you (shhh don’t tell anyone that)
